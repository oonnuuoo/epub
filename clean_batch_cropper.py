#!/usr/bin/env python3
"""
æ§‹æ–‡ä¿®æ­£ç‰ˆãƒãƒƒãƒç”»åƒãƒˆãƒªãƒŸãƒ³ã‚°ãƒ—ãƒ­ã‚°ãƒ©ãƒ 
æ–°ã—ã„ãƒˆãƒªãƒŸãƒ³ã‚°åŸºæº–:
1. ç”»åƒä¸­å¤®ã‹ã‚‰90%ã®ç¯„å›²å†…ã§ã‚³ãƒ³ãƒ†ãƒ³ãƒ„æ¤œå‡º
2. ãƒ”ã‚¯ã‚»ãƒ«ã®æ˜åº¦å€¤ã‚’ä½¿ç”¨ã—ã¦ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’åˆ¤å®š
3. æ¤œå‡ºã•ã‚ŒãŸã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®å‘¨å›²ã®ç™½ã„ä½™ç™½ã‚’é™¤å»

å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒª:
pip install opencv-python pillow numpy tqdm

ä½¿ç”¨æ–¹æ³•:
python clean_batch_cropper.py --input_dir "./images" --output_dir "./cropped"
"""

import os
import argparse
import cv2
import numpy as np
from PIL import Image
import logging
from pathlib import Path
from tqdm import tqdm
import time


class TextAreaCropper:
    """ãƒ†ã‚­ã‚¹ãƒˆé ˜åŸŸè‡ªå‹•ãƒˆãƒªãƒŸãƒ³ã‚°ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, threshold=120, min_margin=0, debug_mode=False):
        """
        åˆæœŸåŒ–
        
        Args:
            threshold (int): äºŒå€¤åŒ–ã®é–¾å€¤ (50-200)
            min_margin (int): æœ€å°ãƒãƒ¼ã‚¸ãƒ³ (0-10)
            debug_mode (bool): ãƒ‡ãƒãƒƒã‚°ãƒ¢ãƒ¼ãƒ‰
        """
        self.threshold = threshold
        self.min_margin = min_margin
        self.debug_mode = debug_mode
        self.setup_logging()
    
    def setup_logging(self):
        """ãƒ­ã‚°è¨­å®š"""
        log_level = logging.DEBUG if self.debug_mode else logging.INFO
        logging.basicConfig(
            level=log_level,
            format='%(asctime)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler('crop_log.txt', encoding='utf-8'),
                logging.StreamHandler()
            ]
        )
        self.logger = logging.getLogger(__name__)
    
    def load_image(self, image_path):
        """ç”»åƒã‚’èª­ã¿è¾¼ã¿"""
        try:
            pil_image = Image.open(image_path)
            if pil_image.mode != 'RGB':
                pil_image = pil_image.convert('RGB')
            
            cv_image = cv2.cvtColor(np.array(pil_image), cv2.COLOR_RGB2BGR)
            height, width = cv_image.shape[:2]
            
            self.logger.info(f"ç”»åƒèª­ã¿è¾¼ã¿æˆåŠŸ: {os.path.basename(image_path)} ({width}x{height})")
            return pil_image, cv_image, width, height
            
        except Exception as e:
            self.logger.error(f"ç”»åƒèª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {os.path.basename(image_path)} - {str(e)}")
            return None
    
    def detect_content_bounds(self, cv_image, width, height):
        """
        ã‚³ãƒ³ãƒ†ãƒ³ãƒ„é ˜åŸŸã®å¢ƒç•Œã‚’æ¤œå‡ºï¼ˆæ˜åº¦ãƒ™ãƒ¼ã‚¹ï¼‰
        """
        # ä¸­å¤®90%ã®æ¤œå‡ºé ˜åŸŸã‚’å®šç¾©
        detection_margin_x = int(width * 0.05)
        detection_margin_y = int(height * 0.05)
        
        detection_left = detection_margin_x
        detection_right = width - detection_margin_x
        detection_top = detection_margin_y
        detection_bottom = height - detection_margin_y
        
        self.logger.info(f"æ¤œå‡ºé ˜åŸŸ: ({detection_left},{detection_top}) - ({detection_right},{detection_bottom})")
        
        # æ¤œå‡ºé ˜åŸŸå†…ã®ç”»åƒã‚’æŠ½å‡º
        detection_roi = cv_image[detection_top:detection_bottom, detection_left:detection_right]
        gray_roi = cv2.cvtColor(detection_roi, cv2.COLOR_BGR2GRAY)
        
        # æ˜åº¦å€¤ãƒ™ãƒ¼ã‚¹ã§ã‚³ãƒ³ãƒ†ãƒ³ãƒ„æ¤œå‡º
        content_mask = self._detect_content_by_brightness(gray_roi)
        
        # ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®å¢ƒç•Œãƒœãƒƒã‚¯ã‚¹ã‚’æ¤œå‡º
        content_bounds = self._find_content_bounding_box(content_mask)
        
        if content_bounds is None:
            self.logger.warning("ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãŒæ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ")
            return {
                'left': int(width * 0.1),
                'top': int(height * 0.1),
                'right': int(width * 0.9),
                'bottom': int(height * 0.9),
                'width': int(width * 0.8),
                'height': int(height * 0.8)
            }
        
        # æ¤œå‡ºé ˜åŸŸã®åº§æ¨™ã‚’å…¨ä½“åº§æ¨™ã«å¤‰æ›
        content_left = detection_left + content_bounds['left']
        content_top = detection_top + content_bounds['top']
        content_right = detection_left + content_bounds['right']
        content_bottom = detection_top + content_bounds['bottom']
        
        # ç™½ã„ä½™ç™½ã‚’é™¤å»
        final_bounds = self._remove_white_margins(
            cv_image, content_left, content_top, content_right, content_bottom
        )
        
        text_bounds = {
            'left': final_bounds['left'],
            'top': final_bounds['top'],
            'right': final_bounds['right'],
            'bottom': final_bounds['bottom'],
            'width': final_bounds['right'] - final_bounds['left'] + 1,
            'height': final_bounds['bottom'] - final_bounds['top'] + 1
        }
        
        # ãƒ­ã‚°å‡ºåŠ›
        left_margin = final_bounds['left']
        right_margin = width - final_bounds['right']
        top_margin = final_bounds['top']
        bottom_margin = height - final_bounds['bottom']
        
        self.logger.info(f"ã‚³ãƒ³ãƒ†ãƒ³ãƒ„æ¤œå‡ºçµæœ - ä½™ç™½ L:{left_margin} R:{right_margin} T:{top_margin} B:{bottom_margin}")
        
        return text_bounds
    
    def _detect_content_by_brightness(self, gray_roi):
        """æ˜åº¦å€¤ãƒ™ãƒ¼ã‚¹ã§ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’æ¤œå‡º"""
        # æ˜åº¦çµ±è¨ˆã‚’è¨ˆç®—
        mean_brightness = np.mean(gray_roi)
        std_brightness = np.std(gray_roi)
        
        # å‹•çš„é–¾å€¤ã‚’è¨ˆç®—
        brightness_threshold = mean_brightness - std_brightness * 0.5
        final_threshold = min(brightness_threshold, self.threshold)
        
        # ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãƒã‚¹ã‚¯ã‚’ä½œæˆ
        content_mask = gray_roi < final_threshold
        
        # ãƒã‚¤ã‚ºé™¤å»
        kernel = np.ones((3, 3), np.uint8)
        content_mask = cv2.morphologyEx(content_mask.astype(np.uint8), cv2.MORPH_CLOSE, kernel)
        content_mask = cv2.morphologyEx(content_mask, cv2.MORPH_OPEN, kernel)
        
        # å°ã•ãªé ˜åŸŸã‚’é™¤å»
        content_mask = self._remove_small_regions(content_mask, min_area=50)
        
        content_pixels = np.sum(content_mask)
        total_pixels = gray_roi.size
        content_ratio = content_pixels / total_pixels
        
        self.logger.debug(f"æ˜åº¦æ¤œå‡º: å¹³å‡={mean_brightness:.1f}, é–¾å€¤={final_threshold:.1f}, æ¯”ç‡={content_ratio:.1%}")
        
        return content_mask.astype(bool)
    
    def _remove_small_regions(self, mask, min_area=50):
        """å°ã•ãªé ˜åŸŸã‚’é™¤å»"""
        num_labels, labels, stats, _ = cv2.connectedComponentsWithStats(mask.astype(np.uint8), connectivity=8)
        filtered_mask = np.zeros_like(mask)
        
        for i in range(1, num_labels):
            area = stats[i, cv2.CC_STAT_AREA]
            if area >= min_area:
                filtered_mask[labels == i] = 1
        
        return filtered_mask
    
    def _find_content_bounding_box(self, content_mask):
        """ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®å¢ƒç•Œãƒœãƒƒã‚¯ã‚¹ã‚’æ¤œå‡º"""
        if not np.any(content_mask):
            return None
        
        coords = np.column_stack(np.where(content_mask))
        if len(coords) == 0:
            return None
        
        top = np.min(coords[:, 0])
        bottom = np.max(coords[:, 0])
        left = np.min(coords[:, 1])
        right = np.max(coords[:, 1])
        
        return {
            'left': left,
            'top': top,
            'right': right,
            'bottom': bottom
        }
    
    def _remove_white_margins(self, cv_image, left, top, right, bottom):
        """ç™½ã„ä½™ç™½ã‚’é™¤å»"""
        roi = cv_image[top:bottom+1, left:right+1]
        gray_roi = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)
        
        white_threshold = 240
        adjusted_bounds = self._scan_white_margins(gray_roi, white_threshold)
        
        return {
            'left': left + adjusted_bounds['left'],
            'top': top + adjusted_bounds['top'],
            'right': left + adjusted_bounds['right'],
            'bottom': top + adjusted_bounds['bottom']
        }
    
    def _scan_white_margins(self, gray_roi, white_threshold):
        """å„æ–¹å‘ã‹ã‚‰ç™½ã„ä½™ç™½ã‚’ã‚¹ã‚­ãƒ£ãƒ³"""
        height, width = gray_roi.shape
        
        # ä¸Šã‹ã‚‰ä¸‹ã¸ã‚¹ã‚­ãƒ£ãƒ³
        top_trim = 0
        for y in range(height):
            if np.mean(gray_roi[y, :]) < white_threshold:
                top_trim = max(0, y - 2)
                break
        
        # ä¸‹ã‹ã‚‰ä¸Šã¸ã‚¹ã‚­ãƒ£ãƒ³
        bottom_trim = height - 1
        for y in range(height - 1, -1, -1):
            if np.mean(gray_roi[y, :]) < white_threshold:
                bottom_trim = min(height - 1, y + 2)
                break
        
        # å·¦ã‹ã‚‰å³ã¸ã‚¹ã‚­ãƒ£ãƒ³
        left_trim = 0
        for x in range(width):
            if np.mean(gray_roi[:, x]) < white_threshold:
                left_trim = max(0, x - 2)
                break
        
        # å³ã‹ã‚‰å·¦ã¸ã‚¹ã‚­ãƒ£ãƒ³
        right_trim = width - 1
        for x in range(width - 1, -1, -1):
            if np.mean(gray_roi[:, x]) < white_threshold:
                right_trim = min(width - 1, x + 2)
                break
        
        # å¦¥å½“æ€§ãƒã‚§ãƒƒã‚¯
        if left_trim >= right_trim or top_trim >= bottom_trim:
            self.logger.warning("ç™½ä½™ç™½é™¤å»ã§ç„¡åŠ¹ãªå¢ƒç•ŒãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸ")
            return {
                'left': 0,
                'top': 0,
                'right': width - 1,
                'bottom': height - 1
            }
        
        return {
            'left': left_trim,
            'top': top_trim,
            'right': right_trim,
            'bottom': bottom_trim
        }
    
    def crop_image(self, pil_image, text_bounds):
        """ç”»åƒã‚’ãƒˆãƒªãƒŸãƒ³ã‚°"""
        left = max(0, text_bounds['left'] - self.min_margin)
        top = max(0, text_bounds['top'] - self.min_margin)
        right = min(pil_image.width - 1, text_bounds['right'] + self.min_margin)
        bottom = min(pil_image.height - 1, text_bounds['bottom'] + self.min_margin)
        
        cropped = pil_image.crop((left, top, right + 1, bottom + 1))
        
        original_area = pil_image.width * pil_image.height
        cropped_area = cropped.width * cropped.height
        reduction = ((original_area - cropped_area) / original_area) * 100
        
        self.logger.info(f"ãƒˆãƒªãƒŸãƒ³ã‚°å®Œäº†: {cropped.width}x{cropped.height} (å‰Šæ¸›ç‡: {reduction:.1f}%)")
        
        return cropped
    
    def process_image(self, input_path, output_path):
        """å˜ä¸€ç”»åƒã®å‡¦ç†"""
        try:
            result = self.load_image(input_path)
            if result is None:
                return False
            
            pil_image, cv_image, width, height = result
            text_bounds = self.detect_content_bounds(cv_image, width, height)
            
            if text_bounds['width'] <= 0 or text_bounds['height'] <= 0:
                self.logger.warning(f"æœ‰åŠ¹ãªé ˜åŸŸãŒæ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ: {os.path.basename(input_path)}")
                return False
            
            cropped_image = self.crop_image(pil_image, text_bounds)
            
            os.makedirs(os.path.dirname(output_path), exist_ok=True)
            cropped_image.save(output_path, quality=95, optimize=True)
            
            self.logger.info(f"ä¿å­˜å®Œäº†: {os.path.basename(output_path)}")
            return True
            
        except Exception as e:
            self.logger.error(f"å‡¦ç†ã‚¨ãƒ©ãƒ¼: {os.path.basename(input_path)} - {str(e)}")
            return False


def get_image_files(directory):
    """ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‹ã‚‰ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã‚’å–å¾—"""
    image_extensions = {'.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.tif', '.webp'}
    image_files = []
    
    for root, dirs, files in os.walk(directory):
        for file in files:
            if Path(file).suffix.lower() in image_extensions:
                image_files.append(os.path.join(root, file))
    
    return sorted(image_files)


def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    parser = argparse.ArgumentParser(description='ç°¡ç´ åŒ–ç‰ˆãƒãƒƒãƒç”»åƒãƒˆãƒªãƒŸãƒ³ã‚°ãƒ—ãƒ­ã‚°ãƒ©ãƒ ')
    parser.add_argument('--input_dir', '-i', required=True, help='å…¥åŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãƒ‘ã‚¹')
    parser.add_argument('--output_dir', '-o', default='./cropped', help='å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãƒ‘ã‚¹')
    parser.add_argument('--threshold', '-t', type=int, default=120, help='äºŒå€¤åŒ–é–¾å€¤ (50-200)')
    parser.add_argument('--margin', '-m', type=int, default=0, help='æœ€å°ãƒãƒ¼ã‚¸ãƒ³ (0-10)')
    parser.add_argument('--preserve_structure', '-p', action='store_true', help='ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ ã‚’ä¿æŒ')
    parser.add_argument('--debug', '-d', action='store_true', help='ãƒ‡ãƒãƒƒã‚°ãƒ¢ãƒ¼ãƒ‰')
    
    args = parser.parse_args()
    
    print("ğŸ–¼ï¸ ç°¡ç´ åŒ–ç‰ˆãƒãƒƒãƒã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãƒˆãƒªãƒŸãƒ³ã‚°ãƒ—ãƒ­ã‚°ãƒ©ãƒ  v2.1")
    print("ğŸ“‹ æ–°ãƒˆãƒªãƒŸãƒ³ã‚°åŸºæº–:")
    print("   1. ç”»åƒä¸­å¤®90%ç¯„å›²ã§ã‚³ãƒ³ãƒ†ãƒ³ãƒ„æ¤œå‡º")
    print("   2. æ˜åº¦å€¤ãƒ™ãƒ¼ã‚¹ã®ã‚·ãƒ³ãƒ—ãƒ«ãªåˆ¤å®š")
    print("   3. å‘¨å›²ç™½ä½™ç™½ã®è‡ªå‹•é™¤å»")
    print("=" * 60)
    
    # å…¥åŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ç¢ºèª
    if not os.path.exists(args.input_dir):
        print(f"ã‚¨ãƒ©ãƒ¼: å…¥åŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒå­˜åœ¨ã—ã¾ã›ã‚“: {args.input_dir}")
        return
    
    # ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«å–å¾—
    image_files = get_image_files(args.input_dir)
    if not image_files:
        print(f"ã‚¨ãƒ©ãƒ¼: ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {args.input_dir}")
        return
    
    print(f"ç™ºè¦‹ã•ã‚ŒãŸç”»åƒãƒ•ã‚¡ã‚¤ãƒ«: {len(image_files)}å€‹")
    print(f"å…¥åŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {args.input_dir}")
    print(f"å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {args.output_dir}")
    print(f"è¨­å®š - é–¾å€¤: {args.threshold}, ãƒãƒ¼ã‚¸ãƒ³: {args.margin}")
    print("-" * 60)
    
    # ãƒˆãƒªãƒŸãƒ³ã‚°å‡¦ç†
    cropper = TextAreaCropper(
        threshold=args.threshold,
        min_margin=args.margin,
        debug_mode=args.debug
    )
    
    successful = 0
    failed = 0
    start_time = time.time()
    
    for input_path in tqdm(image_files, desc="å‡¦ç†ä¸­"):
        try:
            # å‡ºåŠ›ãƒ‘ã‚¹ç”Ÿæˆ
            if args.preserve_structure:
                rel_path = os.path.relpath(input_path, args.input_dir)
                output_path = os.path.join(args.output_dir, rel_path)
            else:
                filename = os.path.basename(input_path)
                output_path = os.path.join(args.output_dir, filename)
            
            # æ—¢å­˜ãƒ•ã‚¡ã‚¤ãƒ«ã‚¹ã‚­ãƒƒãƒ—
            if os.path.exists(output_path):
                print(f"ã‚¹ã‚­ãƒƒãƒ—ï¼ˆæ—¢å­˜ï¼‰: {os.path.basename(output_path)}")
                continue
            
            # å‡¦ç†å®Ÿè¡Œ
            if cropper.process_image(input_path, output_path):
                successful += 1
            else:
                failed += 1
                
        except KeyboardInterrupt:
            print("\nå‡¦ç†ãŒä¸­æ–­ã•ã‚Œã¾ã—ãŸã€‚")
            break
        except Exception as e:
            print(f"äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼: {os.path.basename(input_path)} - {str(e)}")
            failed += 1
    
    # çµæœè¡¨ç¤º
    elapsed_time = time.time() - start_time
    print("\n" + "=" * 60)
    print("å‡¦ç†å®Œäº†")
    print(f"æˆåŠŸ: {successful}å€‹")
    print(f"å¤±æ•—: {failed}å€‹")
    print(f"å‡¦ç†æ™‚é–“: {elapsed_time:.2f}ç§’")
    if len(image_files) > 0:
        print(f"å¹³å‡å‡¦ç†æ™‚é–“: {elapsed_time/len(image_files):.2f}ç§’/ãƒ•ã‚¡ã‚¤ãƒ«")
    print(f"å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {args.output_dir}")


if __name__ == "__main__":
    main()
